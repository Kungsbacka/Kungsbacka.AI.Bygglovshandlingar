{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "train_df = train_df[train_df[\"annotation_type\"] == \"Rectangle\"][ train_df[\"label\"] == \"skalstock_ok\"]\n",
    "test_df = test_df[test_df[\"annotation_type\"] == \"Rectangle\"][ test_df[\"label\"] == \"skalstock_ok\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "#only keep one person for each task_id\n",
    "train_df = train_df.groupby(\"task_id\").first()\n",
    "test_df = test_df.groupby(\"task_id\").first()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import patches\n",
    "import numpy as np\n",
    "\n",
    "def visualize_image_with_bounding_boxes_colored(df):\n",
    "    \"\"\"\n",
    "    Visualizes an image with bounding boxes, each colored according to the rectanglelabels.\n",
    "    Adds labels and colors to the legend.\n",
    "    \n",
    "    Parameters:\n",
    "    - image_path: Path to the image file.\n",
    "    - bounding_boxes: A list of bounding boxes, where each bounding box is represented as a dictionary\n",
    "      with keys 'x', 'y', 'width', 'height', and optionally 'label'. Coordinates are normalized to [0, 1].\n",
    "    \"\"\"\n",
    "    # Open the image file\n",
    "    img = Image.open(df[\"image\"])\n",
    "    fig, ax = plt.subplots(1)\n",
    "    fig.set_size_inches(10, 10)\n",
    "    ax.imshow(img)\n",
    "    \n",
    "    # Image dimensions\n",
    "    img_width, img_height = img.size\n",
    "    \n",
    "    # Label to color mapping\n",
    "    label_color_map = {\n",
    "        'riktning_text': 'r',\n",
    "        'another_label': 'g',\n",
    "          # Example additional label\n",
    "        # Add more labels and colors as needed\n",
    "    }\n",
    "    \n",
    "\n",
    "    # Denormalize coordinates\n",
    "    x = df['x'] * img_width //100\n",
    "    y = df['y'] * img_height //100\n",
    "    width = df['width'] * img_width //100\n",
    "    height = df['height'] * img_height //100\n",
    "    \n",
    "    # Get color for the label\n",
    "    label = df['label']\n",
    "    color = label_color_map.get(label, 'b')  # Default to blue if label not in map\n",
    "    \n",
    "    # Create a Rectangle patch\n",
    "    rect = patches.Rectangle((x, y), width, height, linewidth=1, edgecolor=color, facecolor='none', label=label)\n",
    "    \n",
    "    # Add the patch to the Axes\n",
    "    ax.add_patch(rect)\n",
    "    \n",
    "    # Create legend from unique labels\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    by_label = dict(zip(labels, handles))  # Removing duplicates\n",
    "    ax.legend(by_label.values(), by_label.keys())\n",
    "    \n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "visualize_image_with_bounding_boxes_colored(train_df.iloc[0]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "#data loader for the dataset\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision.transforms import functional as F\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "class KBABygglovDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, scale = 1):\n",
    "        self.df = df\n",
    "        self.transforms = None\n",
    "        self.scale = scale\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        image = cv2.imread(row[\"image\"])\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB ) \n",
    "        #contour = find_bounding_box(image)\n",
    "        \n",
    "        \n",
    "        # Normalize bounding box coordinates\n",
    "        width, height = row[\"original_width\"], row[\"original_height\"]\n",
    "        target = {}\n",
    "\n",
    "        x1 = row['x'] * width //100 \n",
    "        y1 = row['y'] * height //100\n",
    "        width = row['width'] * width //100\n",
    "        height = row['height'] * height //100\n",
    "        target[\"boxes\"] = torch.as_tensor([[x1,y1, x1 + width, y1 + height]], \n",
    "                                dtype = torch.float32)\n",
    "        target[\"labels\"]=torch.as_tensor([1],\n",
    "                        dtype = torch.int64)\n",
    "        target[\"image_id\"] = torch.as_tensor(idx)\n",
    "        #scale the image and target to half size\n",
    "        image = cv2.resize(image, (image.shape[1]// self.scale,  image.shape[0]// self.scale))\n",
    "\n",
    "        target[\"boxes\"] = target[\"boxes\"]/ self.scale\n",
    "\n",
    "        image = F.to_tensor(image)\n",
    "        #cropped_image, target = crop_to_contour(image, target, contour)\n",
    "        return image, target\n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "dataset = KBABygglovDataset(train_df)\n",
    "test_dataset = KBABygglovDataset(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "for data in dataset:\n",
    "    image, boxes = data\n",
    "    image.to(\"cpu\")\n",
    "    #print(boxes)\n",
    "    #print(image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Collate image-target pairs into a tuple.\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "# Create the DataLoaders from the Datasets. \n",
    "train_dl = torch.utils.data.DataLoader(dataset, \n",
    "                                 batch_size = 4, \n",
    "                                 shuffle = True, \n",
    "                        collate_fn = collate_fn)\n",
    "'''val_dl = torch.utils.data.DataLoader(val_ds, \n",
    "                             batch_size = 4, \n",
    "                            shuffle = False, \n",
    "                    collate_fn = collate_fn)'''\n",
    "test_dl = torch.utils.data.DataLoader(test_dataset, \n",
    "                               batch_size = 1, \n",
    "                              shuffle = False, \n",
    "                      collate_fn = collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "def get_object_detection_model(num_classes = 2):\n",
    "\n",
    "    model = fasterrcnn_resnet50_fpn(pretrained = False)\n",
    "\n",
    "    # Replace the original 91 class top layer with a new layer\n",
    "    # tailored for num_classes.\n",
    "    in_feats = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_feats,\n",
    "                                                   num_classes)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def unbatch(batch, device):\n",
    "    \"\"\"\n",
    "    Unbatches a batch of data from the Dataloader.\n",
    "    Inputs\n",
    "        batch: tuple\n",
    "            Tuple containing a batch from the Dataloader.\n",
    "        device: str\n",
    "            Indicates which device (CPU/GPU) to use.\n",
    "    Returns\n",
    "        X: list\n",
    "            List of images.\n",
    "        y: list\n",
    "            List of dictionaries.\n",
    "    \"\"\"\n",
    "    X, y = batch\n",
    "    X = [x.to(device) for x in X]\n",
    "    y = [{k: v.to(device) for k, v in t.items()} for t in y]\n",
    "    return X, y\n",
    "def train_batch(batch, model, optimizer, device):\n",
    "    \"\"\"\n",
    "    Uses back propagation to train a model.\n",
    "    Inputs\n",
    "        batch: tuple\n",
    "            Tuple containing a batch from the Dataloader.\n",
    "        model: torch model\n",
    "        optimizer: torch optimizer\n",
    "        device: str\n",
    "            Indicates which device (CPU/GPU) to use.\n",
    "    Returns\n",
    "        loss: float\n",
    "            Sum of the batch losses.\n",
    "        losses: dict\n",
    "            Dictionary containing the individual losses.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    X, y = unbatch(batch, device = device)\n",
    "    optimizer.zero_grad()\n",
    "    losses = model(X, y)\n",
    "    loss = sum(loss for loss in losses.values())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss, losses\n",
    "@torch.no_grad()\n",
    "def validate_batch(batch, model, optimizer, device):\n",
    "    \"\"\"\n",
    "    Evaluates a model's loss value using validation data.\n",
    "    Inputs\n",
    "        batch: tuple\n",
    "            Tuple containing a batch from the Dataloader.\n",
    "        model: torch model\n",
    "        optimizer: torch optimizer\n",
    "        device: str\n",
    "            Indicates which device (CPU/GPU) to use.\n",
    "    Returns\n",
    "        loss: float\n",
    "            Sum of the batch losses.\n",
    "        losses: dict\n",
    "            Dictionary containing the individual losses.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    X, y = unbatch(batch, device = device)\n",
    "    optimizer.zero_grad()\n",
    "    losses = model(X, y)\n",
    "    loss = sum(loss for loss in losses.values())\n",
    "    return loss, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import functional as F\n",
    "from torch_snippets import Report\n",
    "\n",
    "\n",
    "num_epochs = 20\n",
    "# Assuming 'dataset' is an instance of 'KBABygglovDataset' and 'data_loader' is an instance of 'DataLoader'\n",
    "# Also assuming 'device' is defined (e.g., cuda or cpu)\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "model = get_object_detection_model(num_classes = 2)\n",
    "\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, \n",
    "                        lr = 0.005, \n",
    "                    momentum = 0.9, \n",
    "             weight_decay = 0.0005)\n",
    "\n",
    "\n",
    "log = Report(num_epochs)\n",
    "# FasterRCNN loss names.\n",
    "keys = [\"loss_classifier\", \n",
    "            \"loss_box_reg\", \n",
    "        \"loss_objectness\", \n",
    "        \"loss_rpn_box_reg\"]\n",
    "model.to(device)\n",
    "for epoch in range(num_epochs):\n",
    "    N = len(train_dl)\n",
    "    for ix, batch in enumerate(train_dl):\n",
    "        loss, losses = train_batch(batch, model, \n",
    "                                optimizer, device)\n",
    "        # Record the current train loss.\n",
    "        pos = epoch + (ix + 1) / N\n",
    "        log.record(pos = pos, trn_loss = loss.item(), \n",
    "                    end = \"\\r\")\n",
    "    if test_dl is not None:\n",
    "        N = len(test_dl)\n",
    "        for ix, batch in enumerate(test_dl):\n",
    "            loss, losses = validate_batch(batch, model, \n",
    "                                        optimizer, device)\n",
    "            \n",
    "            # Record the current validation loss.\n",
    "            pos = epoch + (ix + 1) / N\n",
    "            log.record(pos = pos, val_loss = loss.item(), \n",
    "                        end = \"\\r\")\n",
    "log.report_avgs(epoch + 1)\n",
    "log\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'skalstock.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def predict_batch(batch, model, device):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    X, _ = unbatch(batch, device = device)\n",
    "    predictions = model(X)\n",
    "    return [x.cpu() for x in X], predictions\n",
    "def predict(model, data_loader, device = \"cpu\"):\n",
    "    images = []\n",
    "    predictions = []\n",
    "    for i, batch in enumerate(data_loader):\n",
    "        X, p = predict_batch(batch, model, device)\n",
    "        images.append(X)\n",
    "        predictions.append(p)\n",
    "    \n",
    "    return images, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "\n",
    "images, predictions = predict(model, test_dl, device = device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "len(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "def decode_prediction(prediction, \n",
    "                      score_threshold = 0.8, \n",
    "                      nms_iou_threshold = 0.2):\n",
    "    \"\"\"\n",
    "    Inputs\n",
    "        prediction: dict\n",
    "        score_threshold: float\n",
    "        nms_iou_threshold: float\n",
    "    Returns\n",
    "        prediction: tuple\n",
    "    \"\"\"\n",
    "    boxes = prediction[\"boxes\"]\n",
    "    scores = prediction[\"scores\"]\n",
    "    labels = prediction[\"labels\"]\n",
    "    # Remove any low-score predictions.\n",
    "    if score_threshold is not None:\n",
    "        want = scores > score_threshold\n",
    "        boxes = boxes[want]\n",
    "        scores = scores[want]\n",
    "        labels = labels[want]\n",
    "    # Remove any overlapping bounding boxes using NMS.\n",
    "    if nms_iou_threshold is not None:\n",
    "        want = torchvision.ops.nms(boxes = boxes, scores = scores, \n",
    "                                iou_threshold = nms_iou_threshold)\n",
    "        boxes = boxes[want]\n",
    "        scores = scores[want]\n",
    "        labels = labels[want]\n",
    "    return (boxes.cpu().numpy(), \n",
    "            labels.cpu().numpy(), \n",
    "            scores.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Object_detection.object_detection_helper import visualize_image_with_bounding_boxes_colored_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "for i in range(len(images)):\n",
    "    print(i)\n",
    "    visualize_image_with_bounding_boxes_colored_img(images[i][0], predictions[i][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_examples = pd.read_csv(\"test.csv\")\n",
    "negative_examples = negative_examples[negative_examples[\"annotation_type\"] == \"Rectangle\"][ negative_examples[\"label\"] == \"skalstock_saknas\"]\n",
    "negative_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data loader for the dataset\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision.transforms import functional as F\n",
    "import os\n",
    "\n",
    "class KBABygglovDataset_false(torch.utils.data.Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        self.transforms = None\n",
    "        print(len(self.df))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        image_path = self.df.iloc[idx][\"image\"]\n",
    "        image = Image.open(image_path)\n",
    "        image = F.to_tensor(image)\n",
    "        \n",
    "        target = {}\n",
    "        target[\"id\"] = torch.as_tensor(row[\"annotation_id\"])\n",
    "        \n",
    "        return image, target\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_false = KBABygglovDataset_false(negative_examples)\n",
    "false_dl = torch.utils.data.DataLoader(dataset_false, \n",
    "                                 batch_size =1, \n",
    "                                 shuffle = False, \n",
    "                        collate_fn = collate_fn)\n",
    "images, predictions = predict(model, false_dl, device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(images)):\n",
    "    print(i)\n",
    "    print(predictions[i][0])\n",
    "    visualize_image_with_bounding_boxes_colored_img(images[i][0], predictions[i][0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_false[\"path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "for i in range(0, len(false_dl)):\n",
    "    print(i)\n",
    "    print(false_dl.dataset.df[\"annotation_id\"].iloc[i])\n",
    "    visualize_image_with_bounding_boxes_colored(false_dl.dataset.df[\"path\"].iloc[i],json.loads(false_dl.dataset.df[\"label\"].iloc[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "false_dl.dataset.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "json.loads(df[\"label\"].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('../../../data/kba-bygglov/annoteringar/Batch32024-04-17.json') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cu121.m121",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/base-cu121:m121"
  },
  "kernelspec": {
   "display_name": "kba-bygglov",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
