{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96c14819-25c8-42f6-9653-5275545ef908",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e705a123-3c7f-4da3-8c36-e1b8fc7ca94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c7ae7e4-080a-4fe7-bf9e-e5b72098ba62",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df[test_df[\"label\"].isin([\"linje1\", \"linje2\", \"linje3\", \"linje4\", \"linje5\", \"linje6\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513b9dba-0205-4607-a222-2105e6fee544",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab9ac47-3d1e-4e3b-8a57-d6c00ade1fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "drawings = test_df.groupby('task_id').first().reset_index()\n",
    "drawings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ed720b9-3cc0-4967-85b2-2fab18c42f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data loader for the dataset\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision.transforms import functional as F\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "class KBABygglovDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, drawings, df,scale = 4):\n",
    "        self.df = df\n",
    "        self.drawings = drawings\n",
    "        self.transforms = None\n",
    "        self.scale = scale\n",
    "        #self.task_ids = df[\"task_id\"].unique()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.drawings)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        task_id = self.drawings.iloc[idx][\"task_id\"]\n",
    "        rows = self.df[self.df[\"task_id\"] == task_id]\n",
    "        image = cv2.imread(rows.iloc[0][\"image\"])\n",
    "        #contour = find_bounding_box(image)\n",
    "        \n",
    "        \n",
    "        # Normalize bounding box coordinates\n",
    "        width, height = rows.iloc[0][\"original_width\"], rows.iloc[0][\"original_height\"]\n",
    "        target = {}\n",
    "        boxes = []\n",
    "        labels = []\n",
    "\n",
    "        for i, row in rows.iterrows():\n",
    "            x1 = row['x'] * row[\"original_width\"] //100 \n",
    "            y1 = row['y'] * row[\"original_height\"] //100\n",
    "            width = row['width'] * row[\"original_width\"] //100\n",
    "            height = row['height'] * row[\"original_height\"] //100\n",
    "            if width == 0 or height == 0:\n",
    "                print(\"FELLLLLL\", task_id)\n",
    "                print(x1, y1, width, height)\n",
    "                print(row)\n",
    "            boxes.append([x1, y1, x1 + width, y1 + height])\n",
    "            labels.append(1)\n",
    "        target[\"boxes\"] = torch.as_tensor(boxes, \n",
    "                                dtype = torch.float32)\n",
    "        target[\"labels\"]=torch.as_tensor(labels,\n",
    "                        dtype = torch.int64)\n",
    "        target[\"image_id\"] = torch.as_tensor([task_id])\n",
    "        #scale the image and target to half size\n",
    "        image = cv2.resize(image, (image.shape[1]// self.scale,  image.shape[0]// self.scale))\n",
    "\n",
    "        target[\"boxes\"] = target[\"boxes\"]/ self.scale\n",
    "\n",
    "        image = F.to_tensor(image)\n",
    "        #cropped_image, target = crop_to_contour(image, target, contour)\n",
    "        return image, target\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "test_dataset = KBABygglovDataset(drawings, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a06dd434-56a1-4944-a81a-899368be115c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Collate image-target pairs into a tuple.\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "# Create the DataLoaders from the Datasets. \n",
    "\n",
    "test_dl = torch.utils.data.DataLoader(test_dataset, \n",
    "                               batch_size = 1, \n",
    "                              shuffle = False, \n",
    "                      collate_fn = collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "516d1652-537d-488e-8665-14b557ca5728",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3e3d10a1-fa23-475d-9e03-7df95eea6abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('distance_marker.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ba9a129d-27db-4eaa-aa8f-c2f90a17e3ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def unbatch(batch, device):\n",
    "    \"\"\"\n",
    "    Unbatches a batch of data from the Dataloader.\n",
    "    Inputs\n",
    "        batch: tuple\n",
    "            Tuple containing a batch from the Dataloader.\n",
    "        device: str\n",
    "            Indicates which device (CPU/GPU) to use.\n",
    "    Returns\n",
    "        X: list\n",
    "            List of images.\n",
    "        y: list\n",
    "            List of dictionaries.\n",
    "    \"\"\"\n",
    "    X, y = batch\n",
    "    X = [x.to(device) for x in X]\n",
    "    y = [{k: v.to(device) for k, v in t.items()} for t in y]\n",
    "    return X, y\n",
    "def train_batch(batch, model, optimizer, device):\n",
    "    \"\"\"\n",
    "    Uses back propagation to train a model.\n",
    "    Inputs\n",
    "        batch: tuple\n",
    "            Tuple containing a batch from the Dataloader.\n",
    "        model: torch model\n",
    "        optimizer: torch optimizer\n",
    "        device: str\n",
    "            Indicates which device (CPU/GPU) to use.\n",
    "    Returns\n",
    "        loss: float\n",
    "            Sum of the batch losses.\n",
    "        losses: dict\n",
    "            Dictionary containing the individual losses.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    X, y = unbatch(batch, device = device)\n",
    "    optimizer.zero_grad()\n",
    "    losses = model(X, y)\n",
    "    loss = sum(loss for loss in losses.values())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss, losses\n",
    "@torch.no_grad()\n",
    "def validate_batch(batch, model, optimizer, device):\n",
    "    \"\"\"\n",
    "    Evaluates a model's loss value using validation data.\n",
    "    Inputs\n",
    "        batch: tuple\n",
    "            Tuple containing a batch from the Dataloader.\n",
    "        model: torch model\n",
    "        optimizer: torch optimizer\n",
    "        device: str\n",
    "            Indicates which device (CPU/GPU) to use.\n",
    "    Returns\n",
    "        loss: float\n",
    "            Sum of the batch losses.\n",
    "        losses: dict\n",
    "            Dictionary containing the individual losses.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    X, y = unbatch(batch, device = device)\n",
    "    optimizer.zero_grad()\n",
    "    losses = model(X, y)\n",
    "    loss = sum(loss for loss in losses.values())\n",
    "    return loss, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1645dc44-f05a-4842-9716-0f233acae1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def predict_batch(batch, model, device):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    X, _ = unbatch(batch, device = device)\n",
    "    predictions = model(X)\n",
    "    return [x.cpu() for x in X], predictions\n",
    "def predict(model, data_loader, device = \"cpu\"):\n",
    "    images = []\n",
    "    predictions = []\n",
    "    for i, batch in enumerate(data_loader):\n",
    "        X, p = predict_batch(batch, model, device)\n",
    "        images.append(X)\n",
    "        predictions.append(p)\n",
    "    \n",
    "    return images, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc61c36-382d-49ca-8b11-7f8f47c0649d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "images, predictions = predict(model, test_dl, device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80827f6c-238e-42da-a178-8030823d4a62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "83597b32-6612-42b7-a9a9-5267456620e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "def decode_prediction(prediction, \n",
    "                      score_threshold = 0.8, \n",
    "                      nms_iou_threshold = 0.2):\n",
    "    \"\"\"\n",
    "    Inputs\n",
    "        prediction: dict\n",
    "        score_threshold: float\n",
    "        nms_iou_threshold: float\n",
    "    Returns\n",
    "        prediction: tuple\n",
    "    \"\"\"\n",
    "    boxes = prediction[\"boxes\"]\n",
    "    scores = prediction[\"scores\"]\n",
    "    labels = prediction[\"labels\"]\n",
    "    # Remove any low-score predictions.\n",
    "    if score_threshold is not None:\n",
    "        want = scores > score_threshold\n",
    "        boxes = boxes[want]\n",
    "        scores = scores[want]\n",
    "        labels = labels[want]\n",
    "    # Remove any overlapping bounding boxes using NMS.\n",
    "    if nms_iou_threshold is not None:\n",
    "        want = torchvision.ops.nms(boxes = boxes, scores = scores, \n",
    "                                iou_threshold = nms_iou_threshold)\n",
    "        boxes = boxes[want]\n",
    "        scores = scores[want]\n",
    "        labels = labels[want]\n",
    "    return {\"boxes\": boxes, \n",
    "            \"labels\": labels, \n",
    "            \"scores\": scores}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fab89cdd-2bef-4b91-bdbd-7adc2e705ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Object_detection.object_detection_helper import visualize_image_with_bounding_boxes_colored_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908a554f-a086-4318-b2f0-cdbab1f80f14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(len(images)):\n",
    "    print(i)\n",
    "    new_pred = decode_prediction(predictions[i][0], score_threshold = 0.6)\n",
    "    print(new_pred)\n",
    "    visualize_image_with_bounding_boxes_colored_img(images[i][0], new_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beeace84-a8d2-4141-85d4-2d85d36eb777",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cu121.m121",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/base-cu121:m121"
  },
  "kernelspec": {
   "display_name": "kba-bygglov",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
