{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"label\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df[train_df[\"label\"].isin([\"linje1\", \"linje2\", \"linje3\", \"linje4\", \"linje5\", \"linje6\"])]\n",
    "test_df = test_df[test_df[\"label\"].isin([\"linje1\", \"linje2\", \"linje3\", \"linje4\", \"linje5\", \"linje6\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[train_df[\"task_id\"] == 4287]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_drawings = train_df.groupby('task_id').first().reset_index()\n",
    "test_drawings = test_df.groupby('task_id').first().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import patches\n",
    "import numpy as np\n",
    "\n",
    "def visualize_image_with_bounding_boxes_colored(df):\n",
    "    \"\"\"\n",
    "    Visualizes an image with bounding boxes, each colored according to the rectanglelabels.\n",
    "    Adds labels and colors to the legend.\n",
    "    \n",
    "    Parameters:\n",
    "    - image_path: Path to the image file.\n",
    "    - bounding_boxes: A list of bounding boxes, where each bounding box is represented as a dictionary\n",
    "      with keys 'x', 'y', 'width', 'height', and optionally 'label'. Coordinates are normalized to [0, 1].\n",
    "    \"\"\"\n",
    "    # Open the image file\n",
    "    img = Image.open(df[\"image\"])\n",
    "    fig, ax = plt.subplots(1)\n",
    "    fig.set_size_inches(10, 10)\n",
    "    ax.imshow(img)\n",
    "    \n",
    "    # Image dimensions\n",
    "    img_width, img_height = img.size\n",
    "    \n",
    "    # Label to color mapping\n",
    "    label_color_map = {\n",
    "        'riktning_text': 'r',\n",
    "        'another_label': 'g',\n",
    "          # Example additional label\n",
    "        # Add more labels and colors as needed\n",
    "    }\n",
    "    \n",
    "\n",
    "    # Denormalize coordinates\n",
    "    x = df['x'] * img_width //100\n",
    "    y = df['y'] * img_height //100\n",
    "    width = df['width'] * img_width //100\n",
    "    height = df['height'] * img_height //100\n",
    "    \n",
    "    # Get color for the label\n",
    "    label = df['label']\n",
    "    color = label_color_map.get(label, 'b')  # Default to blue if label not in map\n",
    "    \n",
    "    # Create a Rectangle patch\n",
    "    rect = patches.Rectangle((x, y), width, height, linewidth=1, edgecolor=color, facecolor='none', label=label)\n",
    "    \n",
    "    # Add the patch to the Axes\n",
    "    ax.add_patch(rect)\n",
    "    \n",
    "    # Create legend from unique labels\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    by_label = dict(zip(labels, handles))  # Removing duplicates\n",
    "    ax.legend(by_label.values(), by_label.keys())\n",
    "    \n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_image_with_bounding_boxes_colored(train_df.iloc[0]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data loader for the dataset\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision.transforms import functional as F\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "class KBABygglovDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, drawings, df,scale = 1):\n",
    "        self.df = df\n",
    "        self.drawings = drawings\n",
    "        self.transforms = None\n",
    "        self.scale = scale\n",
    "        #self.task_ids = df[\"task_id\"].unique()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.drawings)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        task_id = self.drawings.iloc[idx][\"task_id\"]\n",
    "        rows = self.df[self.df[\"task_id\"] == task_id]\n",
    "        image = cv2.imread(rows.iloc[0][\"image\"])\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB ) \n",
    "        #contour = find_bounding_box(image)\n",
    "        \n",
    "        \n",
    "        # Normalize bounding box coordinates\n",
    "        width, height = rows.iloc[0][\"original_width\"], rows.iloc[0][\"original_height\"]\n",
    "        target = {}\n",
    "        boxes = []\n",
    "        labels = []\n",
    "        lines = [\"linje1\", \"linje2\", \"linje3\", \"linje4\", \"linje5\", \"linje6\"]\n",
    "        for line in lines:\n",
    "            line_rows = rows[rows[\"label\"] == line]\n",
    "            if len(line_rows) == 0:\n",
    "                continue\n",
    "            x1 = line_rows[\"x\"].min()*width//100 - 20\n",
    "            y1 = line_rows[\"y\"].min()*height//100 - 20\n",
    "            x2 = line_rows[\"x\"].max()*width//100 + 20\n",
    "            y2 = line_rows[\"y\"].max()*height//100 + 20\n",
    "            boxes.append([x1, y1, x2, y2])\n",
    "            labels.append(1)\n",
    "        target[\"boxes\"] = torch.as_tensor(boxes, \n",
    "                                dtype = torch.float32)\n",
    "        target[\"labels\"]=torch.as_tensor(labels,\n",
    "                        dtype = torch.int64)\n",
    "        target[\"image_id\"] = torch.as_tensor([task_id])\n",
    "        #scale the image and target to half size\n",
    "        image = cv2.resize(image, (image.shape[1]// self.scale,  image.shape[0]// self.scale))\n",
    "\n",
    "        target[\"boxes\"] = target[\"boxes\"]/ self.scale\n",
    "\n",
    "        image = F.to_tensor(image)\n",
    "        #cropped_image, target = crop_to_contour(image, target, contour)\n",
    "        return image, target\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dataset = KBABygglovDataset(train_drawings, train_df)\n",
    "test_dataset = KBABygglovDataset(test_drawings, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in dataset:\n",
    "    image, boxes = data\n",
    "    image.to(\"cpu\")\n",
    "    print(boxes)\n",
    "    print(image.shape)\n",
    "    fig, ax = plt.subplots(1)\n",
    "    fig.set_size_inches(10, 10)\n",
    "    ax.imshow(image.permute(1, 2, 0))\n",
    "    for box in boxes[\"boxes\"]:\n",
    "        x1, y1, x2, y2 = box\n",
    "        rect = patches.Rectangle((x1, y1), x2-x1, y2-y1, linewidth=1, edgecolor='r', facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collate image-target pairs into a tuple.\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "# Create the DataLoaders from the Datasets. \n",
    "train_dl = torch.utils.data.DataLoader(dataset, \n",
    "                                 batch_size = 4, \n",
    "                                 shuffle = True, \n",
    "                        collate_fn = collate_fn)\n",
    "'''val_dl = torch.utils.data.DataLoader(val_ds, \n",
    "                             batch_size = 4, \n",
    "                            shuffle = False, \n",
    "                    collate_fn = collate_fn)'''\n",
    "test_dl = torch.utils.data.DataLoader(test_dataset, \n",
    "                               batch_size = 1, \n",
    "                              shuffle = False, \n",
    "                      collate_fn = collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "def get_object_detection_model(num_classes = 2):\n",
    "\n",
    "    model = fasterrcnn_resnet50_fpn(pretrained = False)\n",
    "\n",
    "    # Replace the original 91 class top layer with a new layer\n",
    "    # tailored for num_classes.\n",
    "    in_feats = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_feats,\n",
    "                                                   num_classes)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unbatch(batch, device):\n",
    "    \"\"\"\n",
    "    Unbatches a batch of data from the Dataloader.\n",
    "    Inputs\n",
    "        batch: tuple\n",
    "            Tuple containing a batch from the Dataloader.\n",
    "        device: str\n",
    "            Indicates which device (CPU/GPU) to use.\n",
    "    Returns\n",
    "        X: list\n",
    "            List of images.\n",
    "        y: list\n",
    "            List of dictionaries.\n",
    "    \"\"\"\n",
    "    X, y = batch\n",
    "    X = [x.to(device) for x in X]\n",
    "    y = [{k: v.to(device) for k, v in t.items()} for t in y]\n",
    "    return X, y\n",
    "def train_batch(batch, model, optimizer, device):\n",
    "    \"\"\"\n",
    "    Uses back propagation to train a model.\n",
    "    Inputs\n",
    "        batch: tuple\n",
    "            Tuple containing a batch from the Dataloader.\n",
    "        model: torch model\n",
    "        optimizer: torch optimizer\n",
    "        device: str\n",
    "            Indicates which device (CPU/GPU) to use.\n",
    "    Returns\n",
    "        loss: float\n",
    "            Sum of the batch losses.\n",
    "        losses: dict\n",
    "            Dictionary containing the individual losses.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    X, y = unbatch(batch, device = device)\n",
    "    optimizer.zero_grad()\n",
    "    losses = model(X, y)\n",
    "    loss = sum(loss for loss in losses.values())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss, losses\n",
    "@torch.no_grad()\n",
    "def validate_batch(batch, model, optimizer, device):\n",
    "    \"\"\"\n",
    "    Evaluates a model's loss value using validation data.\n",
    "    Inputs\n",
    "        batch: tuple\n",
    "            Tuple containing a batch from the Dataloader.\n",
    "        model: torch model\n",
    "        optimizer: torch optimizer\n",
    "        device: str\n",
    "            Indicates which device (CPU/GPU) to use.\n",
    "    Returns\n",
    "        loss: float\n",
    "            Sum of the batch losses.\n",
    "        losses: dict\n",
    "            Dictionary containing the individual losses.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    X, y = unbatch(batch, device = device)\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    losses = model(X, y)\n",
    "    loss = sum(loss for loss in losses.values())\n",
    "    return loss, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import functional as F\n",
    "import torch_snippets.torch_loader as tl\n",
    "\n",
    "\n",
    "num_epochs =10\n",
    "# Assuming 'dataset' is an instance of 'KBABygglovDataset' and 'data_loader' is an instance of 'DataLoader'\n",
    "# Also assuming 'device' is defined (e.g., cuda or cpu)\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "model = get_object_detection_model(num_classes = 2)\n",
    "\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, \n",
    "                        lr = 0.005, \n",
    "                    momentum = 0.9, \n",
    "             weight_decay = 0.0005)\n",
    "\n",
    "\n",
    "log = tl.Report(num_epochs)\n",
    "# FasterRCNN loss names.\n",
    "keys = [\"loss_classifier\", \n",
    "            \"loss_box_reg\", \n",
    "        \"loss_objectness\", \n",
    "        \"loss_rpn_box_reg\"]\n",
    "model.to(device)\n",
    "for epoch in range(num_epochs):\n",
    "    N = len(train_dl)\n",
    "    for ix, batch in enumerate(train_dl):\n",
    "        loss, losses = train_batch(batch, model, \n",
    "                                optimizer, device)\n",
    "        # Record the current train loss.\n",
    "        pos = epoch + (ix + 1) / N\n",
    "        log.record(pos = pos, trn_loss = loss.item(), \n",
    "                    end = \"\\r\")\n",
    "    if test_dl is not None:\n",
    "        N = len(test_dl)\n",
    "        for ix, batch in enumerate(test_dl):\n",
    "            loss, losses = validate_batch(batch, model, \n",
    "                                        optimizer, device)\n",
    "            \n",
    "            # Record the current validation loss.\n",
    "            pos = epoch + (ix + 1) / N\n",
    "            log.record(pos = pos, val_loss = loss.item(), \n",
    "                        end = \"\\r\")\n",
    "log.report_avgs(epoch + 1)\n",
    "log\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'distance_marker.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def predict_batch(batch, model, device):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    X, _ = unbatch(batch, device = device)\n",
    "    predictions = model(X)\n",
    "    return [x.cpu() for x in X], predictions\n",
    "def predict(model, data_loader, device = \"cpu\"):\n",
    "    images = []\n",
    "    predictions = []\n",
    "    for i, batch in enumerate(data_loader):\n",
    "        X, p = predict_batch(batch, model, device)\n",
    "        images.append(X)\n",
    "        predictions.append(p)\n",
    "    \n",
    "    return images, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "images, predictions = predict(model, test_dl, device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "def decode_prediction(prediction, \n",
    "                      score_threshold = 0.8, \n",
    "                      nms_iou_threshold = 0.2):\n",
    "    \"\"\"\n",
    "    Inputs\n",
    "        prediction: dict\n",
    "        score_threshold: float\n",
    "        nms_iou_threshold: float\n",
    "    Returns\n",
    "        prediction: tuple\n",
    "    \"\"\"\n",
    "    boxes = prediction[\"boxes\"]\n",
    "    scores = prediction[\"scores\"]\n",
    "    labels = prediction[\"labels\"]\n",
    "    # Remove any low-score predictions.\n",
    "    if score_threshold is not None:\n",
    "        want = scores > score_threshold\n",
    "        boxes = boxes[want]\n",
    "        scores = scores[want]\n",
    "        labels = labels[want]\n",
    "    # Remove any overlapping bounding boxes using NMS.\n",
    "    if nms_iou_threshold is not None:\n",
    "        want = torchvision.ops.nms(boxes = boxes, scores = scores, \n",
    "                                iou_threshold = nms_iou_threshold)\n",
    "        boxes = boxes[want]\n",
    "        scores = scores[want]\n",
    "        labels = labels[want]\n",
    "    return (boxes.cpu().numpy(), \n",
    "            labels.cpu().numpy(), \n",
    "            scores.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_iou(box1, box2):\n",
    "    x1_1, y1_1, x2_1, y2_1 = box1\n",
    "    x1_2, y1_2, x2_2, y2_2 = box2\n",
    "    \n",
    "    # Calculate the coordinates of the intersection rectangle\n",
    "    x_left = max(x1_1, x1_2)\n",
    "    y_top = max(y1_1, y1_2)\n",
    "    x_right = min(x2_1, x2_2)\n",
    "    y_bottom = min(y2_1, y2_2)\n",
    "    \n",
    "    # Calculate the area of the intersection rectangle\n",
    "    if x_right < x_left or y_bottom < y_top:\n",
    "        return 0.0  # No overlap\n",
    "    intersection_area = (x_right - x_left) * (y_bottom - y_top)\n",
    "    \n",
    "    # Calculate the areas of both bounding boxes\n",
    "    box1_area = (x2_1 - x1_1) * (y2_1 - y1_1)\n",
    "    box2_area = (x2_2 - x1_2) * (y2_2 - y1_2)\n",
    "    \n",
    "    # Calculate the union area\n",
    "    union_area = box1_area + box2_area - intersection_area\n",
    "    \n",
    "    # Calculate the IoU\n",
    "    iou = intersection_area / union_area\n",
    "    return iou\n",
    "\n",
    "def eliminate_overlapping_boxes(boxes, overlap_threshold=0.8):\n",
    "    # Sort the boxes by area (optional, can improve performance)\n",
    "    boxes = sorted(boxes, key=lambda b: (b[2] - b[0]) * (b[3] - b[1]), reverse=True)\n",
    "    \n",
    "    keep_boxes = []\n",
    "    while boxes:\n",
    "        # Take the first box and compare it with the rest\n",
    "        current_box = boxes.pop(0)\n",
    "        keep = True\n",
    "        \n",
    "        for other_box in keep_boxes:\n",
    "            iou = calculate_iou(current_box, other_box)\n",
    "            if iou > overlap_threshold:\n",
    "                keep = False\n",
    "                break\n",
    "        \n",
    "        if keep:\n",
    "            keep_boxes.append(current_box)\n",
    "    \n",
    "    return keep_boxes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_image_with_bounding_boxes_colored_img(img, bounding_boxes):\n",
    "    \"\"\"\n",
    "    Visualizes an image with bounding boxes, each colored according to the rectanglelabels.\n",
    "    Adds labels and colors to the legend.\n",
    "    \n",
    "    Parameters:\n",
    "    - image_path: Path to the image file.\n",
    "    - bounding_boxes: A list of bounding boxes, where each bounding box is represented as a dictionary\n",
    "      with keys 'x', 'y', 'width', 'height', and optionally 'label'. Coordinates are normalized to [0, 1].\n",
    "    \"\"\"\n",
    "    # Open the image file\n",
    "    fig, ax = plt.subplots(1)\n",
    "    fig.set_size_inches(10, 10)\n",
    "    ax.imshow(img.permute(1, 2, 0).numpy())\n",
    "    \n",
    "    # Image dimensions\n",
    "    img_width, img_height = img.shape[0], img.shape[1]\n",
    "    \n",
    "    # Label to color mapping\n",
    "    label_color_map = {\n",
    "        'riktning_text': 'r',\n",
    "        'another_label': 'g',  # Example additional label\n",
    "        # Add more labels and colors as needed\n",
    "    }\n",
    "    print(bounding_boxes[\"scores\"].cpu())\n",
    "    if len(bounding_boxes[\"scores\"].cpu()) != 0:\n",
    "        print(np.argmax(bounding_boxes[\"scores\"].cpu()))\n",
    "        # Add bounding boxes\n",
    "        for i in range(len(bounding_boxes[\"boxes\"].cpu())):\n",
    "            # Denormalize coordinates\n",
    "            if bounding_boxes[\"scores\"].cpu()[i] < 0.5:\n",
    "                continue\n",
    "            box = bounding_boxes[\"boxes\"].cpu()[i]\n",
    "\n",
    "            print(box)\n",
    "            x = box[0] \n",
    "            y = box[1]\n",
    "            width = box[2]-box[0]\n",
    "            height = box[3]-box[1]\n",
    "            \n",
    "            # Create a Rectangle patch\n",
    "            rect = patches.Rectangle((x, y), width, height, linewidth=1, edgecolor=\"red\", facecolor='none', label=1)\n",
    "            \n",
    "            # Add the patch to the Axes\n",
    "            ax.add_patch(rect)\n",
    "    \n",
    "    # Create legend from unique labels\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    by_label = dict(zip(labels, handles))  # Removing duplicates\n",
    "    ax.legend(by_label.values(), by_label.keys())\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from Object_detection.object_detection_helper import visualize_image_with_bounding_boxes_colored_img\n",
    "for i in range(len(images)):\n",
    "    print(i)\n",
    "    \n",
    "    visualize_image_with_bounding_boxes_colored_img(images[i][0], predictions[i][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cu121.m121",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/base-cu121:m121"
  },
  "kernelspec": {
   "display_name": "kba-bygglov",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
